{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make(\"CliffWalking-v0\")\n",
    "\n",
    "# The typical imports\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mc import FiniteMCModel as MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#m.score(env, m.pi, n_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "S = 4*12 # [(x, y, z) for x in range(4,22) for y in range(1,11) for z in [True,False]]\n",
    "A = 4 # 2\n",
    "eps = 100000\n",
    "START_EPS = 1\n",
    "# Run a demo of the environment\n",
    "m = MC(S, A, epsilon=START_EPS)\n",
    "for i in range(1, eps+1):\n",
    "    ep = []\n",
    "    observation = env.reset()\n",
    "    while True:\n",
    "        # Choosing behavior policy\n",
    "        action = m.choose_action(m.b, observation)\n",
    "\n",
    "        # Run simulation\n",
    "        next_observation, reward, done, _ = env.step(action)\n",
    "        ep.append((observation, action, reward))\n",
    "        observation = next_observation\n",
    "        if done:\n",
    "            break\n",
    "    m.update_Q(ep)\n",
    "    m.epsilon = START_EPS*(eps-i)/eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = m.score(env, m.b, n_samples=100)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a 3D wireframe like in the example mplot3d/wire3d_demo\n",
    "X = 12\n",
    "Y = 4\n",
    "Fx = np.zeros((Y, X))\n",
    "Fy = np.zeros((Y, X))\n",
    "for y in range(Y):\n",
    "    for x in range(X):\n",
    "        amax = np.argmax(m.Q[x+y*12])\n",
    "        if amax == 0: # UP\n",
    "            Fy[y, x] = -1\n",
    "        elif amax == 1: # RIGHT\n",
    "            Fx[y, x] = 1\n",
    "        elif amax == 2: # DOWN\n",
    "            Fy[y, x] = 1\n",
    "        elif amax == 3: # LEFT\n",
    "            Fx[y, x] = -1\n",
    "plt.quiver(Fx,Fy)\n",
    "\n",
    "# X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "# from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.plot_wireframe(X, Y, Z, rstride=1, cstride=1)\n",
    "# ax.set_xlabel(\"X axis\")\n",
    "# ax.set_ylabel(\"Y axis\")\n",
    "# ax.set_zlabel(\"Return\")\n",
    "# plt.savefig(\"blackjackpolicy.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rewards = []\n",
    "for _ in range(10000):\n",
    "    observation = env.reset()\n",
    "    while True:\n",
    "        action = choose_action(pi, observation, ACTION_SPACE, Q)\n",
    "        # action = env.action_space.sample()\n",
    "        #print(\"Started out with: {}\".format(observation))\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        #print(\"Picked: {}, got obs: {}\".format(action, observation))\n",
    "        if done:\n",
    "            rewards.append(reward)\n",
    "            #print(\"Ended with: {}\".format(reward))\n",
    "            break\n",
    "print(np.mean(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
